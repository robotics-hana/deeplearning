{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OJ8J_m5g3yEH"
      },
      "source": [
        "# Coursework 1: Chest X-ray (100 marks)\n",
        "\n",
        "In this coursework, you will be working with the Kaggle [Chest X-Ray Images (Pneumonia)](https://www.kaggle.com/datasets/paultimothymooney/chest-xray-pneumonia/data) dataset. You will analyze the dataset, and train deep learning models to classify whether an x-ray exhibits pneumonia.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g3nJRr1B3yEK"
      },
      "source": [
        "The coursework is structured as follows:\n",
        "\n",
        "1. Data Analysis: 5 marks\n",
        "2. Data Preparation: 5 marks\n",
        "3. Training a Baseline: 30 marks\n",
        "4. Improving the Baseline: 50 marks\n",
        "5. Evaluating on the Test Set: 10 marks\n",
        "\n",
        "In each question will require you tocode up a solution, and to briefly explain and discuss your choices and results.\n",
        "\n",
        "__IMPORTANT__\n",
        "* Pretrained models are __NOT__ allowed. You will recieve __0__ marks for any use of pretrained models.\n",
        "* The use of LLM/AI support including writing and coding aligns to the UCL guidelines. This includes the use of code prompts and Gemini in Google Collab"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cdf12jco3yEL"
      },
      "source": [
        "Here are some additional tips:\n",
        "- We recommend using weights and biases to log your training runs. This will allow you to easily compare previous runs if needed.\n",
        "- Ensure your results are reproducable - we may rerun your notebook to check for this. Points will be lost if results are not reproducable.\n",
        "- We recommend factorizing your code in places where you will be repeatedly using the same functionaility. For example, if you are training multiple models, consider using a common training loop function.\n",
        "- Your code and results and discussions should be concise, well-presented, and easy to read. Each question has a certain portion of marks going towards this.\n",
        "- Ensure you correctly use the train, validation, and test set throughout. You should only ever use the test set once - for the final evaluation.\n",
        "- Consider saving your models so you can reload previous models for the final evaluation\n",
        "- Ensure it is clear to the reader what any plots / figures are presenting. I.e., label axes, include titles, ensure it is clear what experiment it is from (what model / design choices, etc.)\n",
        "- Google Collab restricts the amount of GPU time available. Consider debugging code, using a subset of data, on CPU compute"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "aBDQxq2e3yEL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e1d42f9-3562-4119-f407-bf5dac3fb138"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.12/dist-packages (1.7.4.5)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.12/dist-packages (from kaggle) (6.3.0)\n",
            "Requirement already satisfied: certifi>=14.05.14 in /usr/local/lib/python3.12/dist-packages (from kaggle) (2025.11.12)\n",
            "Requirement already satisfied: charset-normalizer in /usr/local/lib/python3.12/dist-packages (from kaggle) (3.4.4)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from kaggle) (3.11)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from kaggle) (5.29.5)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.12/dist-packages (from kaggle) (2.9.0.post0)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.12/dist-packages (from kaggle) (8.0.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from kaggle) (2.32.4)\n",
            "Requirement already satisfied: setuptools>=21.0.0 in /usr/local/lib/python3.12/dist-packages (from kaggle) (75.2.0)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.12/dist-packages (from kaggle) (1.17.0)\n",
            "Requirement already satisfied: text-unidecode in /usr/local/lib/python3.12/dist-packages (from kaggle) (1.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from kaggle) (4.67.1)\n",
            "Requirement already satisfied: urllib3>=1.15.1 in /usr/local/lib/python3.12/dist-packages (from kaggle) (2.5.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.12/dist-packages (from kaggle) (0.5.1)\n",
            "Requirement already satisfied: wandb in /usr/local/lib/python3.12/dist-packages (0.23.1)\n",
            "Requirement already satisfied: click>=8.0.1 in /usr/local/lib/python3.12/dist-packages (from wandb) (8.3.1)\n",
            "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from wandb) (3.1.45)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from wandb) (25.0)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.12/dist-packages (from wandb) (4.5.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<7,>=3.19.0 in /usr/local/lib/python3.12/dist-packages (from wandb) (5.29.5)\n",
            "Requirement already satisfied: pydantic<3 in /usr/local/lib/python3.12/dist-packages (from wandb) (2.12.3)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from wandb) (6.0.3)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from wandb) (2.32.4)\n",
            "Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from wandb) (2.47.0)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.8 in /usr/local/lib/python3.12/dist-packages (from wandb) (4.15.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.12)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3->wandb) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<3->wandb) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3->wandb) (0.4.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.0.0->wandb) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.0.0->wandb) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.0.0->wandb) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.0.0->wandb) (2025.11.12)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install kaggle\n",
        "!pip install wandb"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "If you get the following error when running the import cell below this description:\n",
        "\n",
        "\n",
        "```\n",
        "OSError: Could not find kaggle.json. Make sure it's located in /root/.config/kaggle. Or use the environment method. See setup instructions at https://github.com/Kaggle/kaggle-api/\n",
        "```\n",
        "You will need to create a kaggle account, and navigate to https://www.kaggle.com/me/account. Navigate to \"API\" and create a new token. This will automatically download a json file called \"kaggle.json\".\n",
        "\n",
        "Run the following code, replacing the \"INSERT JSON HERE TEXT\" with the contents of the json that you downloaded.\n",
        "\n",
        "```\n",
        "!mkdir /root/.config/kaggle\n",
        "!touch /root/.config/kaggle/kaggle.json\n",
        "\n",
        "api_token = INSERT JSON HERE TEXT\n",
        "\n",
        "import json\n",
        "\n",
        "with open('/root/.config/kaggle/kaggle.json', 'w') as file:\n",
        "    json.dump(api_token, file)\n",
        "\n",
        "!chmod 600 /root/.config/kaggle/kaggle.json\n",
        "```\n",
        "\n",
        "INSERT JSON HERE TEXT should be something of the form:\n",
        "```\n",
        "{\"username\":\"XXX\",\"key\":\"XXX\"}\n",
        "```"
      ],
      "metadata": {
        "id": "MNGPJcxblyhM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir /root/.config/kaggle\n",
        "!touch /root/.config/kaggle/kaggle.json\n",
        "\n",
        "api_token = {\"username\":\"hshshsbhsyugsgygys\",\"key\":\"860ba3e66aad4e0176afc0d5c2231839\"}\n",
        "\n",
        "import json\n",
        "\n",
        "with open('/root/.config/kaggle/kaggle.json', 'w') as file:\n",
        "    json.dump(api_token, file)\n",
        "\n",
        "!chmod 600 /root/.config/kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "Lbexms8SoEHq"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "fzTtYHbX3yEM"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import random\n",
        "import shutil\n",
        "import kaggle\n",
        "from kaggle.api.kaggle_api_extended import KaggleApi\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "import os\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "from collections import Counter\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, WeightedRandomSampler\n",
        "from torchvision import models, transforms\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "import wandb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "_2Y454o63yEN"
      },
      "outputs": [],
      "source": [
        "# Set device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TqB_JTQi3yEN"
      },
      "source": [
        "# Load and Re-split the Raw Data\n",
        "\n",
        "The original data is poorly split, so we will resplit it here. Do NOT edit this code."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "8e2WyfzM3yEN"
      },
      "outputs": [],
      "source": [
        "# Hyperparameters\n",
        "TRAIN_SPLIT = 0.8\n",
        "VAL_SPLIT = 0.1\n",
        "TEST_SPLIT = 0.1  # This is implicitly defined as 1 - (TRAIN_SPLIT + VAL_SPLIT)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LEdJHUHQ3yEN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1f87acef-b5fb-4496-c8a6-389d84f61d2b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading paultimothymooney/chest-xray-pneumonia to chest_xray_dataset\n",
            "Dataset URL: https://www.kaggle.com/datasets/paultimothymooney/chest-xray-pneumonia\n"
          ]
        }
      ],
      "source": [
        "# Set up the Kaggle API\n",
        "api = KaggleApi()\n",
        "api.authenticate()\n",
        "\n",
        "# Specify the dataset\n",
        "dataset = \"paultimothymooney/chest-xray-pneumonia\"\n",
        "\n",
        "# Specify the download path\n",
        "download_path = \"chest_xray_dataset\"\n",
        "\n",
        "# Check if the dataset is already downloaded\n",
        "if os.path.exists(os.path.join(download_path, \"chest_xray\")):\n",
        "    print(f\"Dataset already exists at {download_path}. Skipping download.\")\n",
        "else:\n",
        "    # Create the download directory if it doesn't exist\n",
        "    os.makedirs(download_path, exist_ok=True)\n",
        "\n",
        "    # Download the dataset\n",
        "    print(f\"Downloading {dataset} to {download_path}\")\n",
        "    api.dataset_download_files(dataset, path=download_path, unzip=True)\n",
        "    print(\"Download complete!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "knFl_TAC3yEO"
      },
      "outputs": [],
      "source": [
        "# Re-split data\n",
        "dataset_path = os.path.join(download_path, \"chest_xray\")\n",
        "new_dataset_path = \"chest_xray_dataset_new_split\"\n",
        "\n",
        "if not os.path.exists(new_dataset_path):\n",
        "    # Create new directory structure\n",
        "    for split in ['train', 'val', 'test']:\n",
        "        for cls in ['NORMAL', 'PNEUMONIA']:\n",
        "            os.makedirs(os.path.join(new_dataset_path, split, cls), exist_ok=True)\n",
        "\n",
        "    for cls in ['NORMAL', 'PNEUMONIA']:\n",
        "        all_files = []\n",
        "        for split in ['train', 'val', 'test']:\n",
        "            source_folder = os.path.join(dataset_path, split, cls)\n",
        "            files = os.listdir(source_folder)\n",
        "            all_files.extend([(file, source_folder) for file in files])\n",
        "\n",
        "        # Sort files to ensure consistent order before shuffling\n",
        "        all_files.sort()\n",
        "\n",
        "        # Create a new Random object with the seed\n",
        "        rng = random.Random(42)\n",
        "\n",
        "        # Use the shuffle method of the Random object\n",
        "        rng.shuffle(all_files)\n",
        "\n",
        "        total_files = len(all_files)\n",
        "        train_end = int(total_files * TRAIN_SPLIT)\n",
        "        val_end = int(total_files * (TRAIN_SPLIT + VAL_SPLIT))\n",
        "\n",
        "        train_files = all_files[:train_end]\n",
        "        val_files = all_files[train_end:val_end]\n",
        "        test_files = all_files[val_end:]\n",
        "\n",
        "        for split, file_list in [('train', train_files), ('val', val_files), ('test', test_files)]:\n",
        "            for file, source_folder in file_list:\n",
        "                source = os.path.join(source_folder, file)\n",
        "                dest = os.path.join(new_dataset_path, split, cls, file)\n",
        "                shutil.copy(source, dest)\n",
        "\n",
        "    print(f\"Data re-split complete. New dataset location: {new_dataset_path}\")\n",
        "else:\n",
        "    print(f\"Re-split dataset already exists at {new_dataset_path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BCEwmeP03yEO"
      },
      "source": [
        "# Question 1: Data Analysis (5 marks)\n",
        "\n",
        "Perform some basic analysis of the statistics of the dataset.\n",
        "\n",
        "Try to spot anything that may impact how you will design your deep learning classifier and training.\n",
        "\n",
        "We'd expect to see:\n",
        "* Analysis of labels (target variable);\n",
        "* Analysis of input features;\n",
        "\n",
        "If you do spot anything, briefly explain **how you think it may impact training**.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fcFr_0-h3yEP"
      },
      "outputs": [],
      "source": [
        "# Collect dataset statistics\n",
        "splits = ['train', 'val', 'test']\n",
        "classes = ['NORMAL', 'PNEUMONIA']\n",
        "\n",
        "stats = {split: {cls: 0 for cls in ['NORMAL', 'PNEUMONIA']} for split in ['train', 'val', 'test']}\n",
        "for split in splits:\n",
        "    for cls in classes:\n",
        "        path = os.path.join(new_dataset_path, split, cls)\n",
        "        stats[split][cls] = len(os.listdir(path))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bOewT8sA3yEP"
      },
      "outputs": [],
      "source": [
        "########################################################################\n",
        "#                              YOUR CODE HERE                          #\n",
        "########################################################################\n",
        "#Analysis 1\n",
        "# Print class distribution\n",
        "for split in splits:\n",
        "    total = sum(stats[split].values())\n",
        "    print(f\"\\n{split.upper()} SET:\")\n",
        "    for cls in classes:\n",
        "        count = stats[split][cls]\n",
        "        print(f\"  {cls}: {count} ({count/total:.2%})\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HiuMf1ce3yEP"
      },
      "source": [
        "**Analysis 1**\n",
        "\n",
        "Label distribution analysis:\n",
        "The dataset is significantly imbalanced, with substantially more PNEUMONIA samples than NORMAL across all splits. This imbalance may bias the classifier towards predicting the majority class, potentially inflating accuracy while reducing sensitivity to NORMAL cases.\n",
        "\n",
        "Impact on training:\n",
        "To mitigate this, techniques such as class weighting, data augmentation, or alternative evaluation metrics (e.g. precision, recall, F1-score) should be considered rather than relying solely on accuracy."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Analysis 2\n",
        "\n",
        "sample_images = []\n",
        "\n",
        "for cls in classes:\n",
        "    sample_path = os.path.join(new_dataset_path, 'train', cls)\n",
        "    img_name = os.listdir(sample_path)[0]\n",
        "    img = Image.open(os.path.join(sample_path, img_name))\n",
        "    sample_images.append((cls, img))\n",
        "\n",
        "for cls, img in sample_images:\n",
        "    img_array = np.array(img)\n",
        "    print(f\"\\nClass: {cls}\")\n",
        "    print(\"  Image size:\", img.size)\n",
        "    print(\"  Array shape:\", img_array.shape)\n",
        "    print(\"  Pixel range:\", img_array.min(), \"to\", img_array.max())\n"
      ],
      "metadata": {
        "id": "fzcCCkBVowAN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Analysis 2**\n",
        "\n",
        "Input feature analysis:\n",
        "The dataset contains chest X-ray images with varying spatial resolutions and inconsistent channel formats. Some images are stored as single-channel grayscale images, while others are stored as three-channel RGB images. Pixel intensity ranges also differ between samples.\n",
        "\n",
        "Impact on training:\n",
        "These inconsistencies require preprocessing steps such as resizing images to a fixed resolution, standardising channel format, and normalising pixel values. Without this, the model would be unable to process the inputs consistently and training stability would be negatively affected."
      ],
      "metadata": {
        "id": "eZ_1GmSio9bu"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SDN6YQeP3yEP"
      },
      "source": [
        "# Question 2: Data Preparation (5 marks)\n",
        "\n",
        "Here, you should load the dataset into torch dataloaders, performing any preprocessing required in the process.\n",
        "\n",
        "Within the ChestXrayDataset class, the root_dir parameter is a string defining the directory containing the \"train\", \"val\" and \"test\" folders."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NcBeWbFP3yEP"
      },
      "outputs": [],
      "source": [
        "dataset_path = \"chest_xray_dataset_new_split\"\n",
        "batch_size =12"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "atk7VPI23yEQ"
      },
      "outputs": [],
      "source": [
        "class ChestXrayDataset(Dataset):\n",
        "    def __init__(self, root_dir, split='train', transform=None):\n",
        "        ########################################################################\n",
        "        #                              YOUR CODE HERE                          #\n",
        "        ########################################################################\n",
        "        self.root_dir = root_dir\n",
        "        self.split = split\n",
        "        self.transform = transform\n",
        "\n",
        "        self.classes = ['NORMAL', 'PNEUMONIA']\n",
        "        self.class_to_idx = {cls: i for i, cls in enumerate(self.classes)}\n",
        "\n",
        "        self.images = []  # list of (image_path, label)\n",
        "\n",
        "        for cls in self.classes:\n",
        "            cls_dir = os.path.join(self.root_dir, self.split, cls)\n",
        "            if not os.path.isdir(cls_dir):\n",
        "                raise FileNotFoundError(f\"Missing folder: {cls_dir}\")\n",
        "\n",
        "            for fname in os.listdir(cls_dir):\n",
        "                # basic filtering (helps avoid hidden/system files)\n",
        "                if fname.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
        "                    self.images.append((os.path.join(cls_dir, fname), self.class_to_idx[cls]))\n",
        "\n",
        "        # optional: stable ordering (good for reproducibility)\n",
        "        self.images.sort(key=lambda x: x[0])\n",
        "\n",
        "\n",
        "        ########################################################################\n",
        "        #                             END OF YOUR CODE                         #\n",
        "        ########################################################################\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        ########################################################################\n",
        "        #                              YOUR CODE HERE                          #\n",
        "        ########################################################################\n",
        "        img_path, label = self.images[idx]\n",
        "\n",
        "        # Convert everything to 3-channel RGB to standardise channel shape\n",
        "        image = Image.open(img_path).convert(\"RGB\")\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        label = torch.tensor(label, dtype=torch.long)\n",
        "        return image, label\n",
        "\n",
        "\n",
        "        ########################################################################\n",
        "        #                             END OF YOUR CODE                         #\n",
        "        ########################################################################"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DMEI4zhT3yEQ"
      },
      "outputs": [],
      "source": [
        "# Define data transforms\n",
        "        ########################################################################\n",
        "        #                              YOUR CODE HERE                          #\n",
        "        ########################################################################\n",
        "\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.Resize((128, 128)),\n",
        "    transforms.RandomHorizontalFlip(p=0.5),\n",
        "    transforms.RandomRotation(degrees=10),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.5], std=[0.25])\n",
        "])\n",
        "\n",
        "val_test_transform = transforms.Compose([\n",
        "    transforms.Resize((128, 128)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.5], std=[0.25])\n",
        "])\n",
        "\n",
        "        ########################################################################\n",
        "        #                             END OF YOUR CODE                         #\n",
        "        ########################################################################"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0fa080DI3yEQ"
      },
      "outputs": [],
      "source": [
        "        ########################################################################\n",
        "        #                              YOUR CODE HERE                          #\n",
        "        ########################################################################\n",
        "# Create datasets\n",
        "train_dataset = ChestXrayDataset(dataset_path, split='train', transform=train_transform)\n",
        "val_dataset   = ChestXrayDataset(dataset_path, split='val',   transform=val_test_transform)\n",
        "test_dataset  = ChestXrayDataset(dataset_path, split='test',  transform=val_test_transform)\n",
        "\n",
        "# Create data loaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True,  num_workers=2, pin_memory=True)\n",
        "val_loader   = DataLoader(val_dataset,   batch_size=batch_size, shuffle=False, num_workers=2, pin_memory=True)\n",
        "test_loader  = DataLoader(test_dataset,  batch_size=batch_size, shuffle=False, num_workers=2, pin_memory=True)\n",
        "\n",
        "\n",
        "        ########################################################################\n",
        "        #                             END OF YOUR CODE                         #\n",
        "        ########################################################################\n",
        "\n",
        "\n",
        "# -------------------------\n",
        "# Print dataset sizes\n",
        "# -------------------------\n",
        "print(\"Dataset sizes:\")\n",
        "print(\"  Train:\", len(train_dataset))\n",
        "print(\"  Val  :\", len(val_dataset))\n",
        "print(\"  Test :\", len(test_dataset))\n",
        "\n",
        "# -------------------------\n",
        "# Print batch shapes\n",
        "# -------------------------\n",
        "x, y = next(iter(train_loader))\n",
        "print(\"\\nOne training batch:\")\n",
        "print(\"  Images shape:\", x.shape)   # (B, 3, 224, 224)\n",
        "print(\"  Labels shape:\", y.shape)   # (B,)\n",
        "print(\"  Labels dtype:\", y.dtype)\n",
        "print(\"  Example labels:\", y[:10].tolist())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZelQODT83yEQ"
      },
      "source": [
        "**Design choices:**\n",
        "\n",
        "Images are resized to 224Ã—224 to create a consistent input size for batching and CNN training. The dataset contains mixed channel formats (some grayscale, some RGB), so images are standardised to a consistent channel format (grayscale) to avoid shape mismatches. Pixel values are converted to tensors and normalised to improve optimisation stability. Data augmentation (small rotations and flips) is applied only to the training set to improve generalisation, while validation/test sets use deterministic preprocessing for fair evaluation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ty37YSYK3yEQ"
      },
      "source": [
        "# Question 3: Training a Baseline (30 marks)\n",
        "\n",
        "You will now establish an initial baseline model and training procedure. This should be as simple as possible, without using any elaborate design choices, whilst still obtaining reasonable performance (i.e., at least better than random chance). You will attempt to improve upon this baseline in later questions.\n",
        "\n",
        "When answering this question, consider what makes a good baseline:\n",
        "* Easily converges;\n",
        "* Easy to implement;\n",
        "* Established architectural components that have proved well suited to the data-type and problem.\n",
        "* Obtains reasonable performance e.g, better than random guess\n",
        "\n",
        "You will be required to explain your design choices, and to present and discuss you results.\n",
        "\n",
        "The code below is a suggested structure to guide you. You are free to deviate from this __however, it must be obvious to the marker__:\n",
        "* What the final proposed baseline model is (in terms of architecture);\n",
        "* What the performance of the baseline model is and how the model has been trained;\n",
        "* What your written justification and discussion is;\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RzUuFDRc3yEQ"
      },
      "outputs": [],
      "source": [
        "num_epochs = 10\n",
        "use_wandb = False  # Set to True if you want to use wandb\n",
        "lr = 1e-3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2j6klXIC3yEQ"
      },
      "outputs": [],
      "source": [
        "# Define the model\n",
        "class SimpleModel(nn.Module):\n",
        "\n",
        "        ########################################################################\n",
        "        #                              YOUR CODE HERE                          #\n",
        "        ########################################################################\n",
        "  def __init__(self):\n",
        "        super().__init__()\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Conv2d(3, 8, 3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(2),\n",
        "\n",
        "            nn.Conv2d(8, 16, 3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(2),\n",
        "        )\n",
        "\n",
        "        self.pool = nn.AdaptiveAvgPool2d((1, 1))  # -> (B,16,1,1)\n",
        "\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(16, 32),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(32, 2)\n",
        "        )\n",
        "\n",
        "  def forward(self, x):\n",
        "      x = self.features(x)\n",
        "      x = self.pool(x)\n",
        "      return self.classifier(x)\n",
        "\n",
        "        ########################################################################\n",
        "        #                             END OF YOUR CODE                         #\n",
        "        ########################################################################\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y0xh1jau3yER"
      },
      "outputs": [],
      "source": [
        "def calculate_class_accuracy(outputs, labels):\n",
        "        ########################################################################\n",
        "        #                              YOUR CODE HERE                          #\n",
        "        ########################################################################\n",
        "    preds = outputs.argmax(dim=1)\n",
        "    class_acc = {}\n",
        "    for cls in [0, 1]:\n",
        "        mask = (labels == cls)\n",
        "        if mask.sum().item() == 0:\n",
        "            class_acc[cls] = float('nan')\n",
        "        else:\n",
        "            class_acc[cls] = (preds[mask] == labels[mask]).float().mean().item()\n",
        "    return class_acc\n",
        "\n",
        "\n",
        "        ########################################################################\n",
        "        #                             END OF YOUR CODE                         #\n",
        "        ########################################################################"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def update_confusion(cm, preds, labels):\n",
        "    for p, t in zip(preds.view(-1), labels.view(-1)):\n",
        "        cm[t.long(), p.long()] += 1\n",
        "    return cm\n",
        "\n",
        "def class_accuracy_from_cm(cm):\n",
        "    # row = true class, col = predicted class\n",
        "    accs = {}\n",
        "    for c in range(cm.shape[0]):\n",
        "        denom = cm[c].sum().item()\n",
        "        accs[c] = (cm[c, c].item() / denom) if denom > 0 else float('nan')\n",
        "    return accs\n"
      ],
      "metadata": {
        "id": "avppJ8CWsC_5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7EPsfC5s3yER"
      },
      "outputs": [],
      "source": [
        "def train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=30, device='cuda', use_wandb=False):\n",
        "\n",
        "        ########################################################################\n",
        "        #                              YOUR CODE HERE                          #\n",
        "        ########################################################################\n",
        "\n",
        "    train_losses, val_losses = [], []\n",
        "    train_accuracies, val_accuracies = [], []\n",
        "    train_class_accuracies, val_class_accuracies = [], []\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "\n",
        "        # reset confusion matrices each epoch\n",
        "        cm_train = torch.zeros(2, 2, dtype=torch.long)\n",
        "        cm_val   = torch.zeros(2, 2, dtype=torch.long)\n",
        "\n",
        "        # ---- Train ----\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        correct, total = 0, 0\n",
        "\n",
        "        for x, y in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs} [train]\"):\n",
        "            x, y = x.to(device), y.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(x)\n",
        "            loss = criterion(outputs, y)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item() * x.size(0)\n",
        "            preds = outputs.argmax(dim=1)\n",
        "\n",
        "            correct += (preds == y).sum().item()\n",
        "            total += y.size(0)\n",
        "\n",
        "            # update epoch confusion matrix\n",
        "            cm_train = update_confusion(cm_train, preds.detach().cpu(), y.detach().cpu())\n",
        "\n",
        "        train_loss = running_loss / total\n",
        "        train_acc = correct / total\n",
        "        train_losses.append(train_loss)\n",
        "        train_accuracies.append(train_acc)\n",
        "\n",
        "        train_class_acc = class_accuracy_from_cm(cm_train)\n",
        "        train_class_accuracies.append(train_class_acc)\n",
        "\n",
        "        # ---- Val ----\n",
        "        model.eval()\n",
        "        running_loss = 0.0\n",
        "        correct, total = 0, 0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for x, y in tqdm(val_loader, desc=f\"Epoch {epoch+1}/{num_epochs} [val]\"):\n",
        "                x, y = x.to(device), y.to(device)\n",
        "\n",
        "                outputs = model(x)\n",
        "                loss = criterion(outputs, y)\n",
        "\n",
        "                running_loss += loss.item() * x.size(0)\n",
        "                preds = outputs.argmax(dim=1)\n",
        "\n",
        "                correct += (preds == y).sum().item()\n",
        "                total += y.size(0)\n",
        "\n",
        "                cm_val = update_confusion(cm_val, preds.cpu(), y.cpu())\n",
        "\n",
        "        val_loss = running_loss / total\n",
        "        val_acc = correct / total\n",
        "        val_losses.append(val_loss)\n",
        "        val_accuracies.append(val_acc)\n",
        "\n",
        "        val_class_acc = class_accuracy_from_cm(cm_val)\n",
        "        val_class_accuracies.append(val_class_acc)\n",
        "\n",
        "        print(f\"\\nEpoch {epoch+1}/{num_epochs}: \"\n",
        "              f\"train_loss={train_loss:.4f}, train_acc={train_acc:.4f} | \"\n",
        "              f\"val_loss={val_loss:.4f}, val_acc={val_acc:.4f}\")\n",
        "        print(f\"  Train class acc: NORMAL={train_class_acc[0]:.3f}, PNEUMONIA={train_class_acc[1]:.3f}\")\n",
        "        print(f\"  Val   class acc: NORMAL={val_class_acc[0]:.3f}, PNEUMONIA={val_class_acc[1]:.3f}\\n\")\n",
        "        ########################################################################\n",
        "        #                             END OF YOUR CODE                         #\n",
        "        ########################################################################\n",
        "\n",
        "    return train_losses, train_accuracies, val_losses, val_accuracies, train_class_accuracies, val_class_accuracies\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ONedb4HQ3yER"
      },
      "outputs": [],
      "source": [
        "def plot_training_curves(train_losses, train_accuracies, val_losses, val_accuracies, train_class_accuracies, val_class_accuracies):\n",
        "\n",
        "        ########################################################################\n",
        "        #                              YOUR CODE HERE                          #\n",
        "        ########################################################################\n",
        "\n",
        "    epochs = range(1, len(train_losses) + 1)\n",
        "\n",
        "   # ---- Loss ----\n",
        "    plt.figure()\n",
        "    plt.plot(epochs, train_losses, label=\"Train loss\")\n",
        "    plt.plot(epochs, val_losses, label=\"Val loss\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"Loss\")\n",
        "    plt.title(\"Loss vs Epoch\")\n",
        "    plt.legend()\n",
        "    plt.grid(True, alpha=0.3)\n",
        "    plt.show()\n",
        "\n",
        "    # ---- Accuracy ----\n",
        "    plt.figure()\n",
        "    plt.plot(epochs, train_accuracies, label=\"Train accuracy\")\n",
        "    plt.plot(epochs, val_accuracies, label=\"Val accuracy\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"Accuracy\")\n",
        "    plt.title(\"Accuracy vs Epoch\")\n",
        "    plt.legend()\n",
        "    plt.grid(True, alpha=0.3)\n",
        "    plt.show()\n",
        "\n",
        "    # ---- Per-class accuracy ----\n",
        "    train_normal = [d[0] for d in train_class_accuracies]\n",
        "    train_pneu   = [d[1] for d in train_class_accuracies]\n",
        "    val_normal   = [d[0] for d in val_class_accuracies]\n",
        "    val_pneu     = [d[1] for d in val_class_accuracies]\n",
        "\n",
        "    plt.figure()\n",
        "    plt.plot(epochs, train_normal, label=\"Train NORMAL\")\n",
        "    plt.plot(epochs, train_pneu, label=\"Train PNEUMONIA\")\n",
        "    plt.plot(epochs, val_normal, label=\"Val NORMAL\")\n",
        "    plt.plot(epochs, val_pneu, label=\"Val PNEUMONIA\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"Accuracy\")\n",
        "    plt.title(\"Per-class Accuracy vs Epoch\")\n",
        "    plt.legend()\n",
        "    plt.grid(True, alpha=0.3)\n",
        "    plt.show()\n",
        "        ########################################################################\n",
        "        #                             END OF YOUR CODE                         #\n",
        "        ########################################################################"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "\n",
        "def evaluate_model(model, dataloader, device):\n",
        "    model.eval()\n",
        "    all_preds, all_labels = [], []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for x, y in dataloader:\n",
        "            x = x.to(device)\n",
        "            y = y.to(device)\n",
        "            outputs = model(x)\n",
        "            preds = outputs.argmax(dim=1)\n",
        "\n",
        "            all_preds.extend(preds.cpu().numpy())\n",
        "            all_labels.extend(y.cpu().numpy())\n",
        "\n",
        "    acc = accuracy_score(all_labels, all_preds)\n",
        "    prec = precision_score(all_labels, all_preds)\n",
        "    rec = recall_score(all_labels, all_preds)\n",
        "    f1 = f1_score(all_labels, all_preds)\n",
        "    cm = confusion_matrix(all_labels, all_preds)\n",
        "\n",
        "    print(\"Accuracy :\", f\"{acc:.4f}\")\n",
        "    print(\"Precision:\", f\"{prec:.4f}\")\n",
        "    print(\"Recall   :\", f\"{rec:.4f}\")\n",
        "    print(\"F1-score :\", f\"{f1:.4f}\")\n",
        "    print(\"Confusion Matrix:\\n\", cm)\n",
        "\n",
        "    return acc, prec, rec, f1, cm"
      ],
      "metadata": {
        "id": "7GkpB1pH1gD7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C5bwRdrU3yER"
      },
      "outputs": [],
      "source": [
        "# Initialize the model\n",
        "model = SimpleModel().to(device)\n",
        "\n",
        "# Define loss function and optimizer\n",
        "        ########################################################################\n",
        "        #                              YOUR CODE HERE                          #\n",
        "        ########################################################################\n",
        "\n",
        "num_epochs = 10\n",
        "lr = 1e-3\n",
        "use_wandb = False\n",
        "\n",
        "train_labels = [lbl for _, lbl in train_dataset.images]\n",
        "counts = np.bincount(train_labels, minlength=2)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "\n",
        "        ########################################################################\n",
        "        #                             END OF YOUR CODE                         #\n",
        "        ########################################################################\n",
        "\n",
        "# Train the model\n",
        "train_losses, train_accuracies, val_losses, val_accuracies, train_class_accuracies, val_class_accuracies = train_model(\n",
        "    model, train_loader, val_loader, criterion, optimizer, num_epochs, device, use_wandb\n",
        ")\n",
        "\n",
        "# Plot training curves\n",
        "plot_training_curves(train_losses, train_accuracies, val_losses, val_accuracies, train_class_accuracies, val_class_accuracies)\n",
        "\n",
        "# Save the model\n",
        "torch.save(model.state_dict(), 'chest_xray_model.pth')\n",
        "print(\"Model saved as 'chest_xray_model.pth'\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kPUy57xr3yER"
      },
      "source": [
        "**Brief explanation of design choice:**\n",
        "\n",
        "_Insert brief explanation of the design choices you made_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wy-HoUkkecEr"
      },
      "source": [
        "**Results**\n",
        "\n",
        "*Baseline performance:*\n",
        "The baseline CNN was trained for 10 epochs using standard cross-entropy loss and Adam optimisation. Figure X shows the training and validation loss curves, which decrease steadily, indicating stable convergence. Figure Y shows the corresponding accuracy curves.\n",
        "\n",
        "On the validation set, the baseline model achieved an accuracy of 90.26%, with a precision of 0.945, recall of 0.920, and F1-score of 0.932. The confusion matrix (Table X) indicates that most classification errors arise from misclassifying NORMAL images as PNEUMONIA, which is consistent with the class imbalance present in the dataset.\n",
        "\n",
        "Per-class performance further highlights this imbalance: the model performs better on the majority class (PNEUMONIA) than on the minority class (NORMAL). Despite this, the baseline substantially outperforms random guessing and provides a strong reference point for subsequent improvements."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"=== Baseline Validation Performance ===\")\n",
        "evaluate_model(model, val_loader, device)\n"
      ],
      "metadata": {
        "id": "5qMhEf3-1lgi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E--x4N1w3yES"
      },
      "source": [
        "**Result discussion**\n",
        "\n",
        "The baseline model achieves a validation accuracy of 90.26% and an F1-score of 0.932, demonstrating that even a simple convolutional architecture can extract meaningful features from chest X-ray images. This performance is substantially better than random guessing and confirms that convolutional neural networks are well suited to this classification task.\n",
        "\n",
        "However, analysis of the confusion matrix and per-class metrics reveals a clear imbalance in performance between the two classes. The model achieves higher precision and recall for the PNEUMONIA class than for the NORMAL class, with a notable proportion of NORMAL images being misclassified as PNEUMONIA. This behaviour is expected given the strong class imbalance in the dataset and the use of standard cross-entropy loss without any imbalance correction.\n",
        "\n",
        "The training and validation curves indicate stable convergence without severe overfitting, although validation accuracy is occasionally higher than training accuracy due to data augmentation and regularisation applied during training. Overall, while the baseline model provides strong initial performance, its sensitivity to class imbalance and limited architectural capacity suggest several avenues for improvement. In particular, explicitly addressing class imbalance, strengthening the feature extractor, and refining the training strategy are likely to improve both balanced performance and overall robustness."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sq5YLFof3yES"
      },
      "source": [
        "# Question 4: Improving the Baseline (50 marks)\n",
        "After analysing the results of your baseline, can you spot any clear areas for improvement, or think of any obvious improvements to your model and training setup that will improve performance?\n",
        "\n",
        "You are free to try out as many improvements as you want here. You may also try modifying aspects of the data.\n",
        "\n",
        "**However, for the final code and results you present in your submission, you should use exactly 3 design choices which (attempt to) improve upon the baseline.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s8C8cR5govik"
      },
      "source": [
        "Tips:\n",
        "* If you struggle to improve upon the baseline, but your design choices are well motivated and well implemented, and your results are well-presented and discussed, you will still receive most marks here. You will get some extra marks for improving upon baseline performance, but you will primarily be marked for making reasonable design choices.\n",
        "* A small number of marks will be deducted if there are extremely obvious issues with the baseline that you do not attempt to address"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gJb8yLNffD22"
      },
      "source": [
        "## Q 4.1: Final improved model -- baseline + 3 improvements (20 marks)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b0ARZtLmgDGh"
      },
      "source": [
        "You should now choose three final improvements. Explain them, implement them, train a model, and present and discuss the results.\n",
        "\n",
        "Try to maximize performance with the final three improvements you choose (i.e., pick the three best improvements you found)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0e1-IBUhg_Xj"
      },
      "outputs": [],
      "source": [
        "# Implement the improvements and train the model in as many cells as you need.\n",
        "#Add weights to smooth performance\n",
        "########################################################################\n",
        "#                              YOUR CODE HERE                          #\n",
        "########################################################################\n",
        "\n",
        "# Initialize the model\n",
        "model = SimpleModel().to(device)\n",
        "\n",
        "# Define loss function and optimizer\n",
        "num_epochs = 10\n",
        "lr = 1e-3\n",
        "use_wandb = False\n",
        "\n",
        "train_labels = [lbl for _, lbl in train_dataset.images]\n",
        "counts = np.bincount(train_labels, minlength=2)  # <-- add this\n",
        "weights = 1.0 / counts\n",
        "weights = weights / weights.sum() * 2\n",
        "class_weights = torch.tensor(weights, dtype=torch.float32).to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
        "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "# Train the model\n",
        "train_losses, train_accuracies, val_losses, val_accuracies, train_class_accuracies, val_class_accuracies = train_model(\n",
        "    model, train_loader, val_loader, criterion, optimizer, num_epochs, device, use_wandb\n",
        ")\n",
        "\n",
        "# Plot training curves\n",
        "plot_training_curves(train_losses, train_accuracies, val_losses, val_accuracies, train_class_accuracies, val_class_accuracies)\n",
        "\n",
        "# Save the model\n",
        "torch.save(model.state_dict(), 'chest_xray_model.pth')\n",
        "print(\"Model saved as 'chest_xray_model.pth'\")\n",
        "\n",
        "print(\"=== Baseline Validation Performance ===\")\n",
        "evaluate_model(model, val_loader, device)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class ImprovedModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Conv2d(3, 16, 3, padding=1),\n",
        "            nn.BatchNorm2d(16),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(2),\n",
        "\n",
        "            nn.Conv2d(16, 32, 3, padding=1),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(2),\n",
        "\n",
        "            nn.Conv2d(32, 64, 3, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(inplace=True),\n",
        "        )\n",
        "\n",
        "        self.pool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(64, 64),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(64, 2)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = self.pool(x)\n",
        "        return self.classifier(x)\n"
      ],
      "metadata": {
        "id": "n5F35m1VLz_4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Implement the improvements and train the model in as many cells as you need.\n",
        "#Add weights to smooth performance\n",
        "########################################################################\n",
        "#                              YOUR CODE HERE                          #\n",
        "########################################################################\n",
        "\n",
        "# Initialize the model\n",
        "model = ImprovedModel().to(device)\n",
        "\n",
        "# Define loss function and optimizer\n",
        "num_epochs = 10\n",
        "lr = 1e-3\n",
        "use_wandb = False\n",
        "\n",
        "train_labels = [lbl for _, lbl in train_dataset.images]\n",
        "counts = np.bincount(train_labels, minlength=2)  # <-- add this\n",
        "weights = 1.0 / counts\n",
        "weights = weights / weights.sum() * 2\n",
        "class_weights = torch.tensor(weights, dtype=torch.float32).to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
        "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "# Train the model\n",
        "train_losses, train_accuracies, val_losses, val_accuracies, train_class_accuracies, val_class_accuracies = train_model(\n",
        "    model, train_loader, val_loader, criterion, optimizer, num_epochs, device, use_wandb\n",
        ")\n",
        "\n",
        "# Plot training curves\n",
        "plot_training_curves(train_losses, train_accuracies, val_losses, val_accuracies, train_class_accuracies, val_class_accuracies)\n",
        "\n",
        "# Save the model\n",
        "torch.save(model.state_dict(), 'chest_xray_model.pth')\n",
        "print(\"Model saved as 'chest_xray_model.pth'\")\n",
        "\n",
        "print(\"=== Baseline Validation Performance ===\")\n",
        "evaluate_model(model, val_loader, device)"
      ],
      "metadata": {
        "id": "Q5WEjZO_L6d_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Add scheduler\n",
        "\n",
        "def train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=30, device='cuda', use_wandb=False):\n",
        "\n",
        "        ########################################################################\n",
        "        #                              YOUR CODE HERE                          #\n",
        "        ########################################################################\n",
        "\n",
        "    train_losses, val_losses = [], []\n",
        "    train_accuracies, val_accuracies = [], []\n",
        "    train_class_accuracies, val_class_accuracies = [], []\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "\n",
        "        # reset confusion matrices each epoch\n",
        "        cm_train = torch.zeros(2, 2, dtype=torch.long)\n",
        "        cm_val   = torch.zeros(2, 2, dtype=torch.long)\n",
        "\n",
        "        # ---- Train ----\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        correct, total = 0, 0\n",
        "\n",
        "        for x, y in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs} [train]\"):\n",
        "            x, y = x.to(device), y.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(x)\n",
        "            loss = criterion(outputs, y)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            scheduler.step()\n",
        "\n",
        "            running_loss += loss.item() * x.size(0)\n",
        "            preds = outputs.argmax(dim=1)\n",
        "\n",
        "            correct += (preds == y).sum().item()\n",
        "            total += y.size(0)\n",
        "\n",
        "            # update epoch confusion matrix\n",
        "            cm_train = update_confusion(cm_train, preds.detach().cpu(), y.detach().cpu())\n",
        "\n",
        "        train_loss = running_loss / total\n",
        "        train_acc = correct / total\n",
        "        train_losses.append(train_loss)\n",
        "        train_accuracies.append(train_acc)\n",
        "\n",
        "        train_class_acc = class_accuracy_from_cm(cm_train)\n",
        "        train_class_accuracies.append(train_class_acc)\n",
        "\n",
        "        # ---- Val ----\n",
        "        model.eval()\n",
        "        running_loss = 0.0\n",
        "        correct, total = 0, 0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for x, y in tqdm(val_loader, desc=f\"Epoch {epoch+1}/{num_epochs} [val]\"):\n",
        "                x, y = x.to(device), y.to(device)\n",
        "\n",
        "                outputs = model(x)\n",
        "                loss = criterion(outputs, y)\n",
        "\n",
        "                running_loss += loss.item() * x.size(0)\n",
        "                preds = outputs.argmax(dim=1)\n",
        "\n",
        "                correct += (preds == y).sum().item()\n",
        "                total += y.size(0)\n",
        "\n",
        "                cm_val = update_confusion(cm_val, preds.cpu(), y.cpu())\n",
        "\n",
        "        val_loss = running_loss / total\n",
        "        val_acc = correct / total\n",
        "        val_losses.append(val_loss)\n",
        "        val_accuracies.append(val_acc)\n",
        "\n",
        "        val_class_acc = class_accuracy_from_cm(cm_val)\n",
        "        val_class_accuracies.append(val_class_acc)\n",
        "\n",
        "        print(f\"\\nEpoch {epoch+1}/{num_epochs}: \"\n",
        "              f\"train_loss={train_loss:.4f}, train_acc={train_acc:.4f} | \"\n",
        "              f\"val_loss={val_loss:.4f}, val_acc={val_acc:.4f}\")\n",
        "        print(f\"  Train class acc: NORMAL={train_class_acc[0]:.3f}, PNEUMONIA={train_class_acc[1]:.3f}\")\n",
        "        print(f\"  Val   class acc: NORMAL={val_class_acc[0]:.3f}, PNEUMONIA={val_class_acc[1]:.3f}\\n\")\n",
        "        ########################################################################\n",
        "        #                             END OF YOUR CODE                         #\n",
        "        ########################################################################\n",
        "\n",
        "    return train_losses, train_accuracies, val_losses, val_accuracies, train_class_accuracies, val_class_accuracies\n"
      ],
      "metadata": {
        "id": "NYsrNeDw9u1w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Implement the improvements and train the model in as many cells as you need.\n",
        "#Add scheduler\n",
        "########################################################################\n",
        "#                              YOUR CODE HERE                          #\n",
        "########################################################################\n",
        "\n",
        "# Initialize the model\n",
        "model = SimpleModel().to(device)\n",
        "\n",
        "# Define loss function and optimizer\n",
        "num_epochs = 10\n",
        "lr = 1e-3\n",
        "use_wandb = False\n",
        "\n",
        "train_labels = [lbl for _, lbl in train_dataset.images]\n",
        "counts = np.bincount(train_labels, minlength=2)  # <-- add this\n",
        "weights = 1.0 / counts\n",
        "weights = weights / weights.sum() * 2\n",
        "class_weights = torch.tensor(weights, dtype=torch.float32).to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
        "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.5)\n",
        "\n",
        "# Train the model\n",
        "train_losses, train_accuracies, val_losses, val_accuracies, train_class_accuracies, val_class_accuracies = train_model(\n",
        "    model, train_loader, val_loader, criterion, optimizer, num_epochs, device, use_wandb\n",
        ")\n",
        "\n",
        "# Plot training curves\n",
        "plot_training_curves(train_losses, train_accuracies, val_losses, val_accuracies, train_class_accuracies, val_class_accuracies)\n",
        "\n",
        "# Save the model\n",
        "torch.save(model.state_dict(), 'chest_xray_model.pth')\n",
        "print(\"Model saved as 'chest_xray_model.pth'\")\n",
        "\n",
        "print(\"=== Baseline Validation Performance ===\")\n",
        "evaluate_model(model, val_loader, device)"
      ],
      "metadata": {
        "id": "RnL4lA2H9ht5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Add BatchNorm + a slightly deeper CNN\n",
        "\n",
        "class ImprovedModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Conv2d(3, 16, 3, padding=1),\n",
        "            nn.BatchNorm2d(16),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(2),\n",
        "\n",
        "            nn.Conv2d(16, 32, 3, padding=1),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(2),\n",
        "\n",
        "            nn.Conv2d(32, 64, 3, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(inplace=True),\n",
        "        )\n",
        "\n",
        "        self.pool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(64, 64),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(64, 2)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = self.pool(x)\n",
        "        return self.classifier(x)\n"
      ],
      "metadata": {
        "id": "5aQKztLb78_x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Implement the improvements and train the model in as many cells as you need.\n",
        "#Add scheduler\n",
        "########################################################################\n",
        "#                              YOUR CODE HERE                          #\n",
        "########################################################################\n",
        "\n",
        "# Initialize the model\n",
        "model = SimpleModel().to(device)\n",
        "\n",
        "# Define loss function and optimizer\n",
        "num_epochs = 10\n",
        "lr = 1e-3\n",
        "use_wandb = False\n",
        "\n",
        "train_labels = [lbl for _, lbl in train_dataset.images]\n",
        "counts = np.bincount(train_labels, minlength=2)  # <-- add this\n",
        "weights = 1.0 / counts\n",
        "weights = weights / weights.sum() * 2\n",
        "class_weights = torch.tensor(weights, dtype=torch.float32).to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
        "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.5)\n",
        "\n",
        "# Train the model\n",
        "train_losses, train_accuracies, val_losses, val_accuracies, train_class_accuracies, val_class_accuracies = train_model(\n",
        "    model, train_loader, val_loader, criterion, optimizer, num_epochs, device, use_wandb\n",
        ")\n",
        "\n",
        "# Plot training curves\n",
        "plot_training_curves(train_losses, train_accuracies, val_losses, val_accuracies, train_class_accuracies, val_class_accuracies)\n",
        "\n",
        "# Save the model\n",
        "torch.save(model.state_dict(), 'chest_xray_model.pth')\n",
        "print(\"Model saved as 'chest_xray_model.pth'\")\n",
        "\n",
        "print(\"=== Baseline Validation Performance ===\")\n",
        "evaluate_model(model, val_loader, device)"
      ],
      "metadata": {
        "id": "iLl_2y8n62TZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#can either change transform nn linera and and the test transform"
      ],
      "metadata": {
        "id": "JxGJfFaW5J4-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wegv4NKFg3W7"
      },
      "source": [
        "**(a)**\n",
        "\n",
        "*Insert a brief explanation of the three improvements you have used*\n",
        "\n",
        "*For each improvment:*\n",
        "1. *State the change being made;*\n",
        "2. *State **why** this change could, in theory, improve the performance of the baseline model. If possible, motivate your hypothesis using empirical evidence from the baseline models results*\n",
        "\n",
        "\n",
        "add weights, nn.linear to 128 and expand cnn to more layer for faster convergence"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lZc77acWhMEM"
      },
      "source": [
        "**(b)**\n",
        "\n",
        "_Present your results, including plots etc, here_\n",
        "\n",
        "(Hint: ensure you compare to the baseline)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V7z2sLUxhWhd"
      },
      "source": [
        "**(c)**\n",
        "\n",
        "_Discuss your results here_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CIj57HG2fWll"
      },
      "source": [
        "## Q 4.2: Empirically justify improvement 1 (10 marks)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CGgAxZ3hlwVa"
      },
      "source": [
        "Now you will empirically demonstrate the contribution of each improvement to the final performance of your model.\n",
        "\n",
        "To justify the utility of an improvement, you should present one of the following experiments:\n",
        "- *Option 1:* Train the final model _without_ that improvement (but still with the other two improvements). Compare these results to the results you presented previously with all three improvements. If the improvement is useful, removing it should result in a drop in performance\n",
        "- *Option 2:* Compare the performance of baseline to the perfroamnce of the baseline plus a single improvement. If the improvement is useful, you should expect improved performance versus the baseline.\n",
        "\n",
        "You will still get a significant portion of the marks if the proposed improvement was well-motivated but does not empirically improve perfromance. In this case, ensure your discussion touches on why performance may not have improved or any other interesting talking points.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jA2yiCs2nnMp"
      },
      "outputs": [],
      "source": [
        "# Implement the experiment in as many cells as you need.\n",
        "\n",
        "########################################################################\n",
        "#                              YOUR CODE HERE                          #\n",
        "########################################################################"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xk8Uzkgmn4gZ"
      },
      "source": [
        "**(a)**\n",
        "\n",
        "_State the improvement you are justifying_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iCYUpvoYnpbg"
      },
      "source": [
        "**(b)**\n",
        "\n",
        "_Present your results, including plots etc, here_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QEIUdWktnu4Q"
      },
      "source": [
        "**(c)**\n",
        "\n",
        "_Discuss your results here_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6vydel9XfjUv"
      },
      "source": [
        "## Q 4.3: Empirically justify improvement 2 (10 marks)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u_tnhBmLoN2a"
      },
      "outputs": [],
      "source": [
        "# Implement the experiment in as many cells as you need.\n",
        "\n",
        "########################################################################\n",
        "#                              YOUR CODE HERE                          #\n",
        "########################################################################"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IKvOHbc0oEHU"
      },
      "source": [
        "**(a)**\n",
        "\n",
        "_State the improvement you are justifying_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qh-bK3ScoEHc"
      },
      "source": [
        "**(b)**\n",
        "\n",
        "_Present your results, including plots etc, here_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lp8RIsSsoEHc"
      },
      "source": [
        "**(c)**\n",
        "\n",
        "_Discuss your results here_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "goZoEDK-fk0-"
      },
      "source": [
        "## Q 4.4: Empirically justify improvement 3 (10 marks)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QxyMLFtUoOz6"
      },
      "outputs": [],
      "source": [
        "# Implement the experiment in as many cells as you need.\n",
        "\n",
        "########################################################################\n",
        "#                              YOUR CODE HERE                          #\n",
        "########################################################################"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tzu22nM4oCVK"
      },
      "source": [
        "**(a)**\n",
        "\n",
        "_State the improvement you are justifying_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Ywu9x_joCVT"
      },
      "source": [
        "**(b)**\n",
        "\n",
        "_Present your results, including plots etc, here_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ILe3TKZgoCVT"
      },
      "source": [
        "**(c)**\n",
        "\n",
        "_Discuss your results here_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JrteSKJP3yEW"
      },
      "source": [
        "# Question 5: Final Evaluation (10 marks)\n",
        "\n",
        "You should perform a final evaluation of the performance of your model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VPAaD8zD3yEW"
      },
      "outputs": [],
      "source": [
        "# Implement evaluation here\n",
        "\n",
        "########################################################################\n",
        "#                              YOUR CODE HERE                          #\n",
        "########################################################################"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UVzR_Weo3yEW"
      },
      "source": [
        "**(a)**\n",
        "\n",
        "_Present your results, including plots etc, here_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AVQfQU0puHLJ"
      },
      "source": [
        "**(b)**\n",
        "\n",
        "_Discuss your results here_"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "L4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.18"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}